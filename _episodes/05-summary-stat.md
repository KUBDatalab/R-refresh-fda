---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 05-summary-stat.md in _episodes_rmd/
title: "summary statistics"
teaching: 10
exercises: 5
questions:
- "FIX ME"
objectives:
- "FIX ME"
keypoints:
- "FIX ME"

source: Rmd
math: yes
---





## Summary statistics

I vil ofte skulle finde gennemsnit, medianer, standardafvigelser og
andet for jeres data. Og ofte for forskellige grupper. Et af de
første eksempler I kommer til at arbejde med er smagsdommeres 
vurderinger af smagen af kaffe. Og en ting man kunne have lyst til at 
finde ud af om tre forskellige smagsdommere vurderer bitterheden af 
kaffen forskelligt.

Lad os indlæse data:

~~~
kaffe <- read_excel("../data/Results Panel.xlsx")
kaffe
~~~
{: .language-r}



~~~
# A tibble: 192 × 11
   Sample Assessor Replicate Intensity  Sour Bitter Sweet Tobacco Roasted Nutty
   <chr>     <dbl>     <dbl>     <dbl> <dbl>  <dbl> <dbl>   <dbl>   <dbl> <dbl>
 1 31C           1         1      9.3   6.9    6.75  4.5     10.5    7.95  3.9 
 2 31C           1         2      8.7   8.1    7.95  4.35     9.6    8.85  4.8 
 3 31C           1         3      9.75  8.7   10.2   3.9     10.2   10.2   4.8 
 4 31C           1         4     11.7  11.0   11.4   3.15    11.6   10.0   3.45
 5 31C           2         1      8.7   5.7   11.4   6.15    10.6    8.85  1.95
 6 31C           2         2      8.7   9.3   10.4   4.95    11.7   11.0   5.4 
 7 31C           2         3      7.95  9     11.2   1.2     11.1    8.85  4.8 
 8 31C           2         4     10.6  10.0   12.8   1.05    12.3   10.5   1.2 
 9 31C           3         1      8.25  8.85  11.2   4.8     12.8    2.7   2.4 
10 31C           3         2      9.15  8.25  13.4   4.5     13.5    4.8   5.7 
# ℹ 182 more rows
# ℹ 1 more variable: Chocolate <dbl>
~~~
{: .output}

Man kan få et hurtigt overblik ved hjælp af funktionen `summary`:

~~~
summary(kaffe)
~~~
{: .language-r}



~~~
    Sample             Assessor      Replicate      Intensity     
 Length:192         Min.   :1.00   Min.   :1.00   Min.   : 0.750  
 Class :character   1st Qu.:2.75   1st Qu.:1.75   1st Qu.: 7.650  
 Mode  :character   Median :4.50   Median :2.50   Median : 9.450  
                    Mean   :4.50   Mean   :2.50   Mean   : 9.338  
                    3rd Qu.:6.25   3rd Qu.:3.25   3rd Qu.:11.287  
                    Max.   :8.00   Max.   :4.00   Max.   :15.000  
      Sour            Bitter           Sweet           Tobacco      
 Min.   : 1.050   Min.   : 3.000   Min.   : 0.000   Min.   : 0.900  
 1st Qu.: 5.850   1st Qu.: 7.950   1st Qu.: 1.800   1st Qu.: 7.763  
 Median : 8.400   Median :10.050   Median : 3.450   Median :10.200  
 Mean   : 8.044   Mean   : 9.665   Mean   : 3.553   Mean   : 9.627  
 3rd Qu.:10.050   3rd Qu.:11.400   3rd Qu.: 4.950   3rd Qu.:11.550  
 Max.   :15.000   Max.   :15.000   Max.   :12.000   Max.   :15.000  
    Roasted           Nutty         Chocolate     
 Min.   : 1.200   Min.   :0.600   Min.   : 1.050  
 1st Qu.: 7.463   1st Qu.:2.550   1st Qu.: 5.513  
 Median : 9.750   Median :4.050   Median : 7.350  
 Mean   : 9.101   Mean   :4.154   Mean   : 7.426  
 3rd Qu.:10.988   3rd Qu.:5.287   3rd Qu.: 9.450  
 Max.   :15.000   Max.   :9.900   Max.   :15.000  
~~~
{: .output}
En lidt irriterende ting ved dette datasæt er at kolonnen `Sample`
indeholder temperaturen. Men angivet ikke som `31` og så underforstået
i grader Celsius, men i stedet som `31C`. Det er selvfølgelig en 
fiks måde at få angivet at vi arbejder med forskellige samples, der
er karakteriseret ved at være ved forskellige temperaturer.
Men det betyder at vi ikke kan lave matematik på temperaturerne, og det har vi undertiden lyst til.

Nu kunne vi så godt tænke os at finde ud af om de otte smagsdommere
vurderer eksempelvis bitterhed forskelligt. Er der nogen af dem
der er mere "følsomme" overfor bitterhed end andre. Det kan vi få en
ide om ved at beregne gennemsnittet af deres vurdering af bitterheden
i kaffen for hver af dommerne.
Måske er vi også interesserede i medianen. Eller standardafvigelsen.

Det kan gøres på flere måder. Vi præsenterer her to.

## Aggregate muligheden

Dette er den måde at beregne hvordan hver dommer i gennemsnit 
vurderer bitterheden, som I præsenteres for i undervisningsmaterialet.
Den er lidt bøvlet, og kan være vanskelig at vride hjernen omkring.

Den er på den anden side hurtig og nyttig. Og så er det som nævnt den
der er i undervisningsmaterialet, så det er godt at forstå hvad 
der sker.

Funktion vi bruger hedder `aggregate`. Den er indbygget direkte i R.


~~~
aggregate(kaffe, by=list(kaffe$Assessor, kaffe$Sample), FUN = "mean")
~~~
{: .language-r}

~~~
  Group.1 Group.2 Sample Assessor Replicate Intensity    Sour  Bitter  Sweet
1       1     31C     NA        1       2.5    9.8625  8.6625  9.0750 3.9750
2       2     31C     NA        2       2.5    9.0000  8.5125 11.4375 3.3375
3       3     31C     NA        3       2.5    9.2250  9.7500 12.7500 3.6750
4       4     31C     NA        4       2.5    5.7750  6.1500  7.5000 1.9875
5       5     31C     NA        5       2.5    7.0875  6.3375  9.7125 3.3750
6       6     31C     NA        6       2.5    9.6375 10.8000  9.4125 4.1625
  Tobacco Roasted  Nutty Chocolate
1 10.4625  9.2625 4.2375    6.9000
2 11.4375  9.7875 3.3375   10.4625
3 13.5750  6.6375 3.6000    9.1500
4  7.9500  3.8250 2.2500    7.1625
5 10.8750  9.7875 6.1875    7.1250
6 10.7625  6.2625 3.4875    8.1750
~~~
{: .output}

Hvad sker der her? Aggregatefunktionen tager input, data, i dette 
tilfælde dataframen `kaffe`, og splitter den op i et antal grupper.
Grupperne er defineret af hvad vi skriver i `by` argumentet, og vi 
får her to grupper:
Gruppe 1, i outputtet kaldet `Group.1`, og gruppe 2, `Group.2`.



I gruppe 1 har vi dommerne. De har et nummer fra 1 til 8. I gruppe 2 har vi
de forskellige samples de har smagt på. 
Dernæst beregner `aggregate` gennemsnittet af værdierne i *alle* kolonnerne. Det giver os nogle "warnings", fordi vi ikke kan beregne
et gennemsnit af "31C" og "32C", fordi det er tekst, og ikke tal.

Hvordan skal vi læse dem? Vi skal læse dem som at den gennemsnitlige intensitet
som dommer 1 har givet de samples der er kodet som 31C, er 9.8625.

Vil vi beregne andet end gennemsnit, erstatter vi "mean" i `FUN` argumentet med en anden statistisk funktion, det kunne være "median" eller "sd" for medianen hhv. standardafvigelsen.

## Den anden måde.

Arbejdstitel: Summary statistics

mean, median, sd, var - og na.rm

aggregate... Det tager lidt tid for den er 
konceptuelt svær.

Den skal I kende, for det er den der bruges i 
undervisningsmaterialet (og den er i øvrigt fin,
og der er gode argumenter for at bruge den)

Alternativt!
group_by i kombi med summarise.

## En lineær regression

To variable varierer sammen. Plotter vi det kunne det se således
ud:

~~~
kaffe %>% 
  ggplot(aes(Bitter, Sour)) +
  geom_point()
~~~
{: .language-r}

<img src="../fig/rmd-05-unnamed-chunk-4-1.png" alt="plot of chunk unnamed-chunk-4" width="612" style="display: block; margin: auto;" />

Indrømmet måske ikke den mest overbevisende lineære
sammenhæng mellem vurderingen af "Bitter" og "Sour".
Men der er noget.

I en lineær regression, forsøger vi, i dette tilfælde,
at forklare variationen i vurderingen af "Sour", ved
hjælp af variationen i "Bitter". Hvis "Bitter" stiger
med "1", hvor meget stiger "Sour" så med.

Med andre ord, vi vil finde den bedste rette linie at
lægge ind i plottet. Sådan en ret linie beskriver vi
som regel med udtrykket $$y = ax + b$$. Eller:
$$Sour = a*Bitter + b$$
Vil vi have R til at lave beregningerne for os, fortæller vi R hvilken lineære model vi vil fitte data
til. Og hvilke data vi arbejder med:


~~~
model <- lm(Sour ~ Bitter, data = kaffe)
~~~
{: .language-r}

Den første del af funktionen, `Sour ~ Bitter` specificerer
at vi vil beskrive værdierne af `Sour` som funktion af
`Bitter`, i datasættet `kaffe`.

Ser vi på outputtet af det - vi gemte resultatet i
objektet `model` får vi følgende:

~~~
model
~~~
{: .language-r}



~~~

Call:
lm(formula = Sour ~ Bitter, data = kaffe)

Coefficients:
(Intercept)       Bitter  
     3.8600       0.4329  
~~~
{: .output}
Hvilket vi kan læse som:
$$Sour = 0.4329*Bitter + 3.8600$$. Og altså som at
hvis en smagsdommer vurderer bitterheden af kaffen til 
at være 13.2, så forudsiger vores model at smagsdommeren
vil vurdere surheden til at være: $$Sour = 0.4329*13.2 + 3.8600 = 9.57428$$.




Vi kan se flere detaljer:

~~~
summary(model)
~~~
{: .language-r}



~~~

Call:
lm(formula = Sour ~ Bitter, data = kaffe)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.7533 -1.9351  0.1727  1.5054  6.1402 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  3.85995    0.68098   5.668 5.29e-08 ***
Bitter       0.43289    0.06795   6.371 1.39e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.496 on 190 degrees of freedom
Multiple R-squared:  0.176,	Adjusted R-squared:  0.1717 
F-statistic: 40.59 on 1 and 190 DF,  p-value: 1.386e-09
~~~
{: .output}
Her ser vi koefficienterne fra den rette linies ligning, og får også
p-værdierne for dem. Forskellige statistiske tests kalder p-værdien forskellige ting. Her bruges "Pr".

Bemærk at de meget fine p-værdier ikke i sig selv fortæller at der er en sammenhæng, blot at vi med stor sikkerhed kan afvise at koefficienterne skulle være 0.

Bemærk også at $$R^2$$ kun er 0.176, hvilket kan tolkes som at denne lineære model
forklarer 17.6% af variationen i `Sour`. Fantastiske p-værdier, elendig model!

Det allerførste vi ser ovenfor, er statistik på `residualerne`. Det kan vi forstå
som den del af variationen af `Sour`, der ikke forklares af den lineære model. I eksemplet ovenfor, hvor en smagsdommer vurderede
"bitter" til 13.2 forudså modellen at samme smagsdommer skulle vurdere "Sour" til 9.57428. Kigger vi i data, kan vi finde en 
smagsdommer der faktisk vurderer "Bitter" til 13.2. Men samme smagsdommers vurdering af "Sour" er faktisk 11.6. 11.6 - 9.57428 er forskellen på de faktiske data, og det vores lineære model forudsiger. Eller "residualen", den del af variationen i "Sour" som modellen *ikke* forklarer.

{% include links.md %}
